#! /bin/bash

set -e

#########################################################
#
# Platform: NCI Gadi HPC
# Description: Creates input file for fastqc_run_parallel.pbs
#  for all samples in <cohort>.config
# Files are processed from largest to smallest for optimum E.
# Usage: Create <cohort>.config file using template.
# sh fastqc_make_input.sh <cohort>
# Author: Tracy Chew
# tracy.chew@sydney.edu.au
# Date last modified: 27/08/2020
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
#
########################################################

# Description: Obtain multiQC report
# from an analysis directory
# Change input variables below

#PBS -P <project>
#PBS -N multiqc
#PBS -l walltime=05:00:00,ncpus=1,mem=32GB,wd
#PBS -q express
#PBS -W umask=022
#PBS -l storage=scratch/<project>
#PBS -o ./Logs/multiqc_all_datasets.o
#PBS -e ./Logs/multiqc_all_datasets.e

module load multiqc/1.9

# CHANGE VARIABLES
config=../Sample_configs/PREDICT-19_FEB22_FULL.config
analysis=trimmed_fastQC

mkdir -p ${outdir}
cohort=$(basename "$config" | cut -d'.' -f 1)
outdir=../QC_reports/${cohort}_${analysis}

# Get all unique datasets
while read -r fastq sampleid dataset reference seqcentre platform run_type library; do
	if [[ ! ${fastq} =~ ^#.*$ ]]; then
		dir=../${dataset}_${analysis}
		datasets+=(${dir})	
	fi
done < "${config}"

# Unique datasets
uniq_datasets=($(echo "${datasets[@]}" | tr ' ' '\n' | sort -u | tr '\n' ' '))

echo "$(date): Performing multiqc for ${#uniq_datasets[@]} datasets: "${uniq_datasets[@]}""

multiqc --interactive ${uniq_datasets[@]} -o ${outdir}
